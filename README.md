# Repository Description/General Info

* notebooks/ contains all jupyter lab notebooks of this repository

* src/ contains all .py files of this repository

    * CalculateExtremeEventTimeSeries.py takes the slp data and calculates extreme event time series based on the 5th percentile of slp in the months of november, december, january, february and march seperately

    * ES_numba.py measures the event synchronization of the extreme event time series in parallel via mpi4py

    * ES_numba.py is written to run on a high performance cluster with the script SlurmParallelES.sh using the workload manager SLURM

* data/ contains the data needed and generated by the code in this repository f.e. the plotted maps and different outputs of the notebooks and the .py files

* getResultsOfCluster.sh gets the results of the high performance cluster

# Requirements

## Python

* install conda with

```
 wget https://repo.anaconda.com/archive/Anaconda3-2020.11-Linux-x86_64.sh

 bash Anaconda3-2020.11-Linux-x86_64.sh

```

* after that, the following should be in .bashrc

```
# >>> conda initialize >>>
# !! Contents within this block are managed by 'conda init' !!
__conda_setup="$('~/anaconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)"
if [ $? -eq 0 ]; then
    eval "$__conda_setup"
else
    if [ -f "~/anaconda3/etc/profile.d/conda.sh" ]; then
        . "~/anaconda3/etc/profile.d/conda.sh"
    else
        export PATH="~/anaconda3/bin:$PATH"
    fi
fi
unset __conda_setup
# <<< conda initialize <<<

```
* this could lead to conda activaing automatically, which can be stopped with the following command

```
conda config --set auto_activate_base false

```

* now, create a conda env based on environment.yaml and the installation dependencies in it

```
conda env create -f environment.yaml

```
* the created env can now be activated or deactivated
```
conda activate <name of env in environment.yml>

conda deactivate

``` 

## Data

* data used for analyses and calculations can be requested at ozansahin92@gmail.com

# TODOS

## Primary Tasks

* plot the nsi complex network measures in a new notebook specifically for the nsi measures
* plot composite plots for SPKAZ, SPRUS, SPAM, PASP, ASP, WESP (if still visible as a significant connection?)

## Secondary Tasks

* add links to data in f.e. dataLinks.txt in input/
* expand the script getResultsOfCluster.sh to get all data and create one single sparse matrix file with new .py file in output/ for taumax= 2,8,16 respectively
* clean up the code and remove unnecessary parts
* add comprehensive description of all parts of this repository and the code to README.md
